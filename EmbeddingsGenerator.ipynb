{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-07-07T11:20:54.215168Z",
     "start_time": "2025-07-07T11:20:46.595571Z"
    }
   },
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import nibabel as nib\n",
    "from PIL import Image"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-07T11:51:25.110041Z",
     "start_time": "2025-07-07T11:51:25.051720Z"
    }
   },
   "cell_type": "code",
   "source": [
    "bbox_json_path = r'C:\\Users\\mchen7\\PyCharmMiscProject\\1bbox_coords.json'\n",
    "image_directory = r'D:\\OneDrive - Imperial College London\\Documents\\Student Projects\\Kaihe Zhang\\TestingData'\n",
    "MODEL_PATH = r'D:\\OneDrive - Imperial College London\\Documents\\Student Projects\\Kaihe Zhang\\14best_clip_lrp01_pca80_512d_no_augment 1.pth'\n",
    "N_CHANNELS = 16\n",
    "IMG_SIZE = 224\n",
    "EMBED_DIM = 256"
   ],
   "id": "ef13d5b80ea7136a",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-07T11:51:27.690565Z",
     "start_time": "2025-07-07T11:51:27.651561Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision.models import resnet50, ResNet50_Weights\n",
    "from torchvision.models import vit_b_16, ViT_B_16_Weights\n",
    "import math\n",
    "\n",
    "class ResNetMultiChannel(nn.Module):\n",
    "    def __init__(self, n_channels=16, embedding_dim=256):\n",
    "        super().__init__()\n",
    "        weights = ResNet50_Weights.IMAGENET1K_V2\n",
    "        resnet = resnet50(weights=weights)\n",
    "        resnet.conv1 = nn.Conv2d(n_channels, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "        with torch.no_grad():\n",
    "            if n_channels == 3:\n",
    "                resnet.conv1.weight.copy_(resnet50(weights=weights).conv1.weight)\n",
    "            else:\n",
    "                w = resnet50(weights=weights).conv1.weight\n",
    "                mean_weight = w.mean(dim=1, keepdim=True)\n",
    "                resnet.conv1.weight.copy_(mean_weight.repeat(1, n_channels, 1, 1))\n",
    "        self.resnet = resnet\n",
    "        self.project = nn.Linear(resnet.fc.in_features, embedding_dim)\n",
    "        self.resnet.fc = nn.Identity()  # 去除原分类头\n",
    "\n",
    "    def forward(self, x):\n",
    "        feats = self.resnet(x)  # (B, 2048)\n",
    "        return self.project(feats)  # (B, embedding_dim)"
   ],
   "id": "b5a7cd50593553a3",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-07T11:58:47.111349Z",
     "start_time": "2025-07-07T11:51:29.948066Z"
    }
   },
   "cell_type": "code",
   "source": [
    "with open(bbox_json_path, 'r') as f:\n",
    "    bbox_coords = json.load(f)\n",
    "patient_ids = [k.replace('seg', '').replace('.nii.gz', '') for k in bbox_coords.keys()]\n",
    "\n",
    "\n",
    "nifti_files = {}\n",
    "for root, _, files in os.walk(image_directory):\n",
    "    for fname in files:\n",
    "        if fname.lower().endswith('.nii') or fname.lower().endswith('.nii.gz'):\n",
    "            base = os.path.splitext(os.path.splitext(fname)[0])[0]\n",
    "            nifti_files[base] = os.path.join(root, fname)\n",
    "\n",
    "def sample_slices(total_slices, n=N_CHANNELS):\n",
    "    if total_slices < n:\n",
    "        idxs = list(range(total_slices)) + [total_slices // 2] * (n - total_slices)\n",
    "        return idxs[:n]\n",
    "    else:\n",
    "        return np.linspace(0, total_slices - 1, n, dtype=int)\n",
    "\n",
    "\n",
    "#from model import ResNetMultiChannel\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "encoder = ResNetMultiChannel(n_channels=N_CHANNELS, embedding_dim=EMBED_DIM).to(DEVICE)\n",
    "state_dict = torch.load(MODEL_PATH, map_location=DEVICE)\n",
    "if any(k.startswith(\"image_encoder.\") for k in state_dict.keys()):\n",
    "    image_encoder_state = {k.replace(\"image_encoder.\", \"\"): v for k, v in state_dict.items() if k.startswith(\"image_encoder.\")}\n",
    "    encoder.load_state_dict(image_encoder_state, strict=False)\n",
    "elif \"image_encoder\" in state_dict:\n",
    "    encoder.load_state_dict(state_dict[\"image_encoder\"], strict=False)\n",
    "else:\n",
    "    encoder.load_state_dict(state_dict, strict=False)\n",
    "encoder.eval()\n",
    "\n",
    "def extract_ct_embedding(patient_id):\n",
    "    matches = []\n",
    "    for ext in [\".nii.gz\", \".nii\"]:\n",
    "        base = patient_id\n",
    "        if base in nifti_files and nifti_files[base].endswith(ext):\n",
    "            matches.append(nifti_files[base])\n",
    "    if not matches:\n",
    "        return None\n",
    "    img_path = matches[0]\n",
    "    seg_key = 'seg' + patient_id.replace('-', '') + '.nii.gz'\n",
    "    if seg_key not in bbox_coords:\n",
    "        return None\n",
    "    try:\n",
    "        vol = nib.load(img_path).get_fdata()\n",
    "        bbox = bbox_coords[seg_key]\n",
    "        x0, x1 = sorted((bbox['x_min'], bbox['x_max']))\n",
    "        y0, y1 = sorted((bbox['y_min'], bbox['y_max']))\n",
    "        z0, z1 = sorted((bbox['z_min'], bbox['z_max']))\n",
    "        roi = vol[x0:x1, y0:y1, z0:z1]\n",
    "        if roi.shape[2] == 0:\n",
    "            return None\n",
    "        slice_idxs = sample_slices(roi.shape[2], n=N_CHANNELS)\n",
    "        imgs = [roi[:, :, i] for i in slice_idxs]\n",
    "        imgs = np.stack(imgs, axis=0)\n",
    "        imgs = (imgs - imgs.min()) / (imgs.max() - imgs.min() + 1e-8)\n",
    "        imgs_resized = []\n",
    "        for i in range(N_CHANNELS):\n",
    "            img = Image.fromarray((imgs[i] * 255).astype(np.uint8))\n",
    "            img = img.resize((IMG_SIZE, IMG_SIZE))\n",
    "            imgs_resized.append(np.array(img, dtype=np.float32) / 255.0)\n",
    "        imgs_tensor = torch.tensor(np.stack(imgs_resized, axis=0), dtype=torch.float).unsqueeze(0).to(DEVICE)\n",
    "        with torch.no_grad():\n",
    "            embedding = encoder(imgs_tensor)\n",
    "        return embedding.cpu().numpy().squeeze()\n",
    "    except Exception as e:\n",
    "        print(f\"{patient_id} false: {e}\")\n",
    "        return None\n",
    "\n",
    "embeddings = []\n",
    "pid_list = []\n",
    "\n",
    "for idx, pid in enumerate(patient_ids):\n",
    "    emb = extract_ct_embedding(pid)\n",
    "    if emb is not None:\n",
    "        embeddings.append(emb)\n",
    "        pid_list.append(pid)\n",
    "    if idx % 10 == 0:\n",
    "        print(f\"{idx} / {len(patient_ids)} deal\")\n",
    "\n",
    "embeddings = np.stack(embeddings, axis=0)\n",
    "df = pd.DataFrame(embeddings)\n",
    "df.insert(0, 'Patient_ID', pid_list)\n",
    "df.to_csv(r'D:\\OneDrive - Imperial College London\\Documents\\Student Projects\\Kaihe Zhang\\externalCT_embeddings_patient_id.csv', index=False)\n",
    "print(\"save\")"
   ],
   "id": "bfdc3a9683ad88cd",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 / 155 deal\n",
      "10 / 155 deal\n",
      "20 / 155 deal\n",
      "30 / 155 deal\n",
      "40 / 155 deal\n",
      "50 / 155 deal\n",
      "60 / 155 deal\n",
      "70 / 155 deal\n",
      "80 / 155 deal\n",
      "90 / 155 deal\n",
      "100 / 155 deal\n",
      "110 / 155 deal\n",
      "120 / 155 deal\n",
      "130 / 155 deal\n",
      "140 / 155 deal\n",
      "LCIO_164 false: Compressed file ended before the end-of-stream marker was reached\n",
      "150 / 155 deal\n",
      "save\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "96641ab412c51f14"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
